# Test openface on Amazon EC2 Linux Instance

[Openface](https://cmusatyalab.github.io/openface/) provide free and open source face recognition with deep neural networks.

1. Create Amazon EC2 Linux Instance.
2. Install docker on that instance follow http://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html#install_docker.
3. Pull preconfigured docker image for openface and then start it:
    docker pull bamos/openface
    docker run --name openface -p 9000:9000 -p 8000:8000 -t -i bamos/openface /bin/bash
   You can also mount the current working directory into the container using -v option:
    docker run --name openface -v /home/ec2-user:/home/ec2-user -p 9000:9000 -p 8000:8000 -t -i bamos/openface /bin/bash
4. Go to openface folder(/root/openface)
    cd /root/openface
   Make a folder called ./training_images/
    mkdir training_images
   Make a subfolder for each person you want to recognize. For example:
    mkdir ./training_images/obama/
    mkdir ./training_images/trump/
5. Copy all your images of each person into the correct sub-folders. Make sure only one face appears in each image. There's no need to crop the image around the face. OpenFace will do that automatically.
   Use below command on EC2 Linux instance to cp the image to docker container:
    docker cp /home/ec2-user/training_images/jacky/20161113_180636.jpg openface:/root/openface/training_images/jacky/
6. Processing training images.
   (1) do pose detection and alignment:
    ./util/align-dlib.py ./training_images/ align outerEyesAndNose ./aligned-images/ --size 96
    This will create a new ./aligned-images/ subfolder with a cropped and aligned version of each of your test images.
   (2) generate the representations from the aligned images:
    ./batch-represent/main.lua -outDir ./generated-embeddings/ -data ./aligned-images/
    After you run this, the ./generated-embeddings/ sub-folder will contain a csv file with the embeddings for each image.
   (3) train your face detection model:
    ./demos/classifier.py train ./generated-embeddings/
    This will generate a new file called ./generated-embeddings/classifier.pkl. This file has the SVM model you'll use to recognize new faces.
    Now you should have a working face recognizer!
7. Recognize faces!
    Pass a test image to the classifier script like this:
    ./demos/classifier.py infer ./generated-embeddings/classifier.pkl test_images/Jacky_20150816_092814.jpg
    You can get a prediction that looks like this:
    === test_images/Jacky_20150816_092814.jpg ===
    Predict jacky with 0.82 confidence.
